# -*- coding: utf-8 -*-
"""Malaria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mx3LPDFyCbTpjjm4mx_dkVMqvXtiKXvy

## Visualisation des données

-------
Examinons les données de plus près.
"""

import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib.image import imread

# Téléchargement et extraction du fichier zip
import requests, zipfile, io
zip_file_url = 'https://moncoachdata.com/wp-content/uploads/cell_images.zip'
r = requests.get(zip_file_url)
z = zipfile.ZipFile(io.BytesIO(r.content))
z.extractall()

# Chemin d'accès du dossier cell_images
my_data_dir = 'cell_images'

# Confirmez que cela retourne 'test' et 'train'
os.listdir(my_data_dir)

test_path = my_data_dir+'/test/'
train_path = my_data_dir+'/train/'

os.listdir(test_path)

os.listdir(train_path)

os.listdir(train_path+'parasitized')[0]

para_cell = train_path+'/parasitized'+'/C59P20thinF_IMG_20150803_113809_cell_41.png'

para_img = imread(para_cell)

plt.imshow(para_img);

para_img.shape

unifected_cell_path = train_path+'uninfected/'+os.listdir(train_path+'/uninfected')[0]
unifected_cell = imread(unifected_cell_path)
plt.imshow(unifected_cell);

"""**Vérifions combien d'images il y a.**"""

len(os.listdir(train_path+'parasitized'))

len(os.listdir(train_path+'uninfected'))

"""**Découvrons les dimensions moyennes de ces images.**"""

unifected_cell.shape

para_img.shape

dim1 = []
dim2 = []
for image_filename in os.listdir(test_path+'uninfected'):

    img = imread(test_path+'uninfected'+'/'+image_filename)
    d1,d2,colors = img.shape
    dim1.append(d1)
    dim2.append(d2)

data = pd.DataFrame({'dim1': dim1, 'dim2': dim2})
sns.jointplot(data=data, x='dim1', y='dim2', kind="reg")

np.mean(dim1)

np.mean(dim2)

image_shape = (130,130,3)

"""### Manipulation des images

C'est généralement une bonne idée de manipuler les images avec une rotation, un redimensionnement et une mise à l'échelle afin que le modèle devienne plus robuste aux différentes images que notre ensemble de données n'a pas. Nous pouvons utiliser le générateur **ImageDataGenerator** pour le faire automatiquement pour nous. Consultez la documentation pour une liste complète de tous les paramètres que vous pouvez utiliser ici !
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_gen = ImageDataGenerator(rotation_range=20, # Faire pivoter l'image de 20 degrés
                               width_shift_range=0.10, # Modifier la largeur de la photo de 10% maximum
                               height_shift_range=0.10, # Modifier la hauteur de la photo de 10% maximum
                               # rescale=1/255, # Redimensionner l'image en la normalisant
                               shear_range=0.1, # shear signifie couper une partie de l'image (max 10%)
                               zoom_range=0.1, # Zoom de 10% maximum
                               horizontal_flip=True, # Autorise le basculement horizontal
                               fill_mode='nearest' # Remplir les pixels manquants avec la valeur remplie la plus proche
                              )

plt.imshow(para_img);

plt.imshow(image_gen.random_transform(para_img));

plt.imshow(image_gen.random_transform(para_img));

"""### Génération de nombreuses images manipulées à partir d'un répertoire


Pour utiliser .flow_from_directory, vous devez organiser les images dans des sous-répertoires. C'est une exigence absolue, sinon la méthode ne fonctionnera pas. Les répertoires ne doivent contenir que les images d'une seule classe, donc un dossier par classe d'images.

Structure nécessaire :

* Dossier de données d'images
    * Classe 1
        * 0.jpg
        * 1.jpg
        * …
    * Classe 2
        * 0.jpg
        * 1.jpg
        * …
    * …
    * Classe n
"""

image_gen.flow_from_directory(train_path)

image_gen.flow_from_directory(test_path)

"""## Création du Modèle"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D

#https://stats.stackexchange.com/questions/148139/rules-for-selecting-convolutional-neural-network-hyperparameters

model = Sequential()

model.add(Conv2D(filters=32, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3,3),input_shape=image_shape, activation='relu',))
model.add(MaxPooling2D(pool_size=(2, 2)))


model.add(Flatten())


model.add(Dense(128))
model.add(Activation('relu'))

# Les couches Dropout aident à réduire l'overfitting en désactivant les neurones de façon aléatoire pendant l'entraînement.
# Ici nous demandons de désactiver aléatoirement 50% des neurones.
model.add(Dropout(0.5))

# Dernière couche, n'oubliez pas c'est binaire, nous utilisons donc la sigmoïde
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

"""### Early Stopping"""

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor='val_loss',patience=2)

"""### Entraînement du Modèle"""

batch_size = 16

train_image_gen = image_gen.flow_from_directory(train_path,
                                               target_size=image_shape[:2],
                                                color_mode='rgb',
                                               batch_size=batch_size,
                                               class_mode='binary')

test_image_gen = image_gen.flow_from_directory(test_path,
                                               target_size=image_shape[:2],
                                               color_mode='rgb',
                                               batch_size=batch_size,
                                               class_mode='binary',shuffle=False)

train_image_gen.class_indices

results = model.fit(train_image_gen,epochs=20,
                              validation_data=test_image_gen,
                             callbacks=[early_stop])

from tensorflow.keras.models import load_model
model.save('malaria_detector.h5')

"""## Évaluation du Modèle"""

losses = pd.DataFrame(model.history.history)

losses[['loss','val_loss']].plot()

model.metrics_names

model.evaluate(test_image_gen)

from tensorflow.keras.preprocessing import image

# https://datascience.stackexchange.com/questions/13894/how-to-get-predictions-with-predict-generator-on-streaming-test-data-in-keras

pred_probabilities = model.predict(test_image_gen)

pred_probabilities

test_image_gen.classes

predictions = pred_probabilities > 0.5

# Numpy peut traiter cela comme True/False pour nous

predictions

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(test_image_gen.classes,predictions))

confusion_matrix(test_image_gen.classes,predictions)

"""## Prédiction sur une image"""

para_cell

my_image = image.load_img(para_cell,target_size=image_shape)

my_image

type(my_image)

my_image = image.img_to_array(my_image)

type(my_image)

my_image.shape

my_image = np.expand_dims(my_image, axis=0)

my_image.shape

(model.predict(my_image) > 0.5).astype('int32')

train_image_gen.class_indices

test_image_gen.class_indices